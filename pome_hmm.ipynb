{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from pomegranate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "  y, sr = librosa.load(file_path) # read .wav file\n",
    "  hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "  win_length = math.floor(sr*0.025) # 25ms frame\n",
    "  # mfcc is 12 x T matrix\n",
    "  mfcc = librosa.feature.mfcc(\n",
    "      y, sr, n_mfcc=12, n_fft=1024,\n",
    "      hop_length=hop_length, win_length=win_length)\n",
    "  # substract mean from mfcc --> normalize mfcc\n",
    "  mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "  # delta feature 1st order and 2nd order\n",
    "  delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "  delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "  # X is 36 x T\n",
    "  X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "  # return T x 36 (transpose of X)\n",
    "  return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "  files = os.listdir(data_dir)\n",
    "  mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "  return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=20):\n",
    "  kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "  kmeans.fit(X)\n",
    "  print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "  return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dich dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apple/anaconda3/envs/voice/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load nguoi dataset\n",
      "Load benh_nhan dataset\n",
      "Load toi dataset\n",
      "Load test_toi dataset\n",
      "Load test_dich dataset\n",
      "Load test_benh_nhan dataset\n",
      "Load test_nguoi dataset\n",
      "vectors (21833, 36)\n",
      "centers (20, 36)\n",
      "centers (20, 36)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__cinit__() takes at most 2 positional arguments (18 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-943d5acb19aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"centers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDiscreteDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111111111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#   dists = [NormalDistribution(5, 1), NormalDistribution(1, 7), NormalDistribution(8,2),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#            NormalDistribution(5, 1), NormalDistribution(1, 7), NormalDistribution(8,2),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpomegranate/distributions/DiscreteDistribution.pyx\u001b[0m in \u001b[0;36mpomegranate.distributions.DiscreteDistribution.DiscreteDistribution.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __cinit__() takes at most 2 positional arguments (18 given)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  class_names = [\"dich\", \"nguoi\", \"benh_nhan\", \"toi\", \"test_toi\", \"test_dich\", \"test_benh_nhan\", \"test_nguoi\"]\n",
    "  dataset = {}\n",
    "  for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "  # Get all vectors in the datasets\n",
    "  all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "  print(\"vectors\", all_vectors.shape)\n",
    "  # Run K-Means algorithm to get clusters\n",
    "  kmeans = clustering(all_vectors)\n",
    "  print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "\n",
    "  dists = [NormalDistribution(5, 1), NormalDistribution(1, 7), NormalDistribution(8,2), \n",
    "           NormalDistribution(5, 1), NormalDistribution(1, 7), NormalDistribution(8,2),\n",
    "           NormalDistribution(5, 1), NormalDistribution(1, 7), NormalDistribution(8,2)]\n",
    "  trans_mat = np.array([\n",
    "      [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "      [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "      [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "      [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "      [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "      [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "  ])\n",
    "  startprob = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "  ends = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
    "    \n",
    "  pome_hmm = HiddenMarkovModel.from_matrix(trans_mat, d1, startprob, ends)\n",
    "  models = {}\n",
    "  for cname in class_names:\n",
    "    if cname[:4] != 'test': \n",
    "      class_vectors = dataset[cname]\n",
    "      # convert all vectors to the cluster index\n",
    "      # dataset['class_name'] = [O^1, ... O^R]\n",
    "      # O^r = (c1, c2, ... ct, ... cT)\n",
    "      # O^r size T x 1\n",
    "      dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "      if cname[:4] != 'test':\n",
    "        X = np.concatenate(dataset[cname])\n",
    "        lengths = list([len(x) for x in dataset[cname]])\n",
    "        print(\"training class\", cname)\n",
    "        pome_hmm.fit(X, algorithm='viterbi')\n",
    "        models[cname] = pome_hmm\n",
    "  print(\"Training done\")\n",
    "\n",
    "  print(\"Testing\")\n",
    "  for true_cname in class_names:\n",
    "    for O in dataset[true_cname]:\n",
    "      score = {cname : model.log_probability(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "      print(true_cname, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('voice': conda)",
   "language": "python",
   "name": "python37664bitvoicecondadb91d8c3466a4438829f78a16d8d338a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
