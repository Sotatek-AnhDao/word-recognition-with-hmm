{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "from collections import defaultdict\n",
    "\n",
    "result = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "  y, sr = librosa.load(file_path) # read .wav file\n",
    "  hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "  win_length = math.floor(sr*0.025) # 25ms frame\n",
    "  # mfcc is 12 x T matrix\n",
    "  mfcc = librosa.feature.mfcc(\n",
    "      y, sr, n_mfcc=12, n_fft=1024,\n",
    "      hop_length=hop_length, win_length=win_length)\n",
    "  # substract mean from mfcc --> normalize mfcc\n",
    "  mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "  # delta feature 1st order and 2nd order\n",
    "  delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "  delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "  # X is 36 x T\n",
    "  X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "  # return T x 36 (transpose of X)\n",
    "  return X.T # hmmlearn use T x N matrix\n",
    "\n",
    "def get_class_data(data_dir):\n",
    "  files = os.listdir(data_dir)\n",
    "  mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "  return mfcc\n",
    "\n",
    "def clustering(X, n_clusters=20):\n",
    "  kmeans = KMeans(n_clusters=n_clusters, n_init=100, random_state=0, verbose=0)\n",
    "  kmeans.fit(X)\n",
    "  print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "  return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apple/anaconda3/envs/voice/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded toi dataset -  113\n",
      "Loaded nguoi dataset -  134\n",
      "Loaded dich dataset -  127\n",
      "Loaded theo dataset -  116\n",
      "Loaded benh_nhan dataset -  196\n",
      "vectors (25723, 36)\n",
      "centers (20, 36)\n",
      "centers (20, 36)\n",
      "Clustering DONE\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"toi\", \"nguoi\", \"dich\",  \"theo\", \"benh_nhan\"]\n",
    "dataset = {}\n",
    "train_dataset = {}\n",
    "for cname in class_names:\n",
    "  dataset[cname] = get_class_data(os.path.join(\"train\", cname))\n",
    "  print(f\"Loaded {cname} dataset - \", len(dataset[cname]))\n",
    "  dataset[cname] = dataset[cname][:-20]\n",
    "\n",
    "  # Get all vectors in the datasets\n",
    "all_train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_train_vectors.shape)\n",
    "  # Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_train_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "print(\"Clustering DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_components = {\n",
    "    # toi |t|~|o|~|i|\n",
    "    \"toi\": 9,\n",
    "    # dich |d|~|i|~|ch|\n",
    "    \"dich\": 9,\n",
    "    # nguoi |ng|~|uo|~|i|\n",
    "    \"nguoi\": 9,\n",
    "    # theo |th|~|e|~|o|\n",
    "    \"theo\": 9,\n",
    "    # benh_nhan |b|~|e|~|nh|~|silent|~|nh|~|a|~|n| \n",
    "    \"benh_nhan\": 18,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== toi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -12723.5455             +nan\n",
      "         2       -9125.1904       +3598.3551\n",
      "         3       -9097.9092         +27.2813\n",
      "         4       -9094.4643          +3.4448\n",
      "         5       -9093.1675          +1.2968\n",
      "         6       -9092.2399          +0.9276\n",
      "         7       -9091.3848          +0.8550\n",
      "         8       -9090.7238          +0.6611\n",
      "         9       -9090.4195          +0.3043\n",
      "        10       -9090.3019          +0.1176\n",
      "        11       -9090.2470          +0.0549\n",
      "        12       -9090.2186          +0.0283\n",
      "        13       -9090.2031          +0.0155\n",
      "        14       -9090.1940          +0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/toi.pkl\n",
      "==== nguoi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -15723.4150             +nan\n",
      "         2      -11954.4632       +3768.9519\n",
      "         3      -11918.5697         +35.8935\n",
      "         4      -11903.6349         +14.9348\n",
      "         5      -11894.8700          +8.7649\n",
      "         6      -11891.5776          +3.2925\n",
      "         7      -11890.4077          +1.1699\n",
      "         8      -11889.9474          +0.4602\n",
      "         9      -11889.7351          +0.2123\n",
      "        10      -11889.6025          +0.1326\n",
      "        11      -11889.4998          +0.1027\n",
      "        12      -11889.4166          +0.0832\n",
      "        13      -11889.3539          +0.0626\n",
      "        14      -11889.3121          +0.0419\n",
      "        15      -11889.2869          +0.0252\n",
      "        16      -11889.2728          +0.0141\n",
      "        17      -11889.2652          +0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/nguoi.pkl\n",
      "==== dich\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -17407.9058             +nan\n",
      "         2      -11582.4098       +5825.4960\n",
      "         3      -11549.2287         +33.1811\n",
      "         4      -11545.7251          +3.5036\n",
      "         5      -11544.5150          +1.2101\n",
      "         6      -11542.6759          +1.8391\n",
      "         7      -11538.3262          +4.3497\n",
      "         8      -11536.0013          +2.3249\n",
      "         9      -11531.2984          +4.7029\n",
      "        10      -11529.7837          +1.5147\n",
      "        11      -11529.7635          +0.0203\n",
      "        12      -11529.7592          +0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/dich.pkl\n",
      "==== theo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -12987.4135             +nan\n",
      "         2       -9946.2311       +3041.1824\n",
      "         3       -9902.0649         +44.1662\n",
      "         4       -9875.2776         +26.7873\n",
      "         5       -9870.4655          +4.8121\n",
      "         6       -9869.9715          +0.4941\n",
      "         7       -9869.6483          +0.3232\n",
      "         8       -9869.3980          +0.2503\n",
      "         9       -9869.1369          +0.2611\n",
      "        10       -9868.6660          +0.4709\n",
      "        11       -9867.8926          +0.7735\n",
      "        12       -9867.2772          +0.6154\n",
      "        13       -9867.0289          +0.2483\n",
      "        14       -9866.9019          +0.1269\n",
      "        15       -9866.7616          +0.1404\n",
      "        16       -9866.5936          +0.1680\n",
      "        17       -9866.4356          +0.1580\n",
      "        18       -9866.3155          +0.1201\n",
      "        19       -9866.2288          +0.0867\n",
      "        20       -9866.1548          +0.0740\n",
      "        21       -9866.0646          +0.0901\n",
      "        22       -9865.8990          +0.1656\n",
      "        23       -9865.3496          +0.5494\n",
      "        24       -9861.5536          +3.7960\n",
      "        25       -9853.5230          +8.0306\n",
      "        26       -9850.4286          +3.0944\n",
      "        27       -9849.7733          +0.6553\n",
      "        28       -9848.8984          +0.8749\n",
      "        29       -9845.2529          +3.6455\n",
      "        30       -9842.1639          +3.0890\n",
      "        31       -9841.7092          +0.4547\n",
      "        32       -9841.5314          +0.1777\n",
      "        33       -9841.4246          +0.1068\n",
      "        34       -9841.3698          +0.0548\n",
      "        35       -9841.3454          +0.0245\n",
      "        36       -9841.3353          +0.0101\n",
      "        37       -9841.3312          +0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/theo.pkl\n",
      "==== benh_nhan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -28083.2378             +nan\n",
      "         2      -24224.5508       +3858.6870\n",
      "         3      -24174.1747         +50.3761\n",
      "         4      -24165.4138          +8.7609\n",
      "         5      -24161.5489          +3.8649\n",
      "         6      -24158.6906          +2.8583\n",
      "         7      -24156.4412          +2.2495\n",
      "         8      -24155.0648          +1.3764\n",
      "         9      -24154.3386          +0.7261\n",
      "        10      -24153.9372          +0.4014\n",
      "        11      -24153.6984          +0.2389\n",
      "        12      -24153.5517          +0.1467\n",
      "        13      -24153.4556          +0.0961\n",
      "        14      -24153.3839          +0.0717\n",
      "        15      -24153.3188          +0.0651\n",
      "        16      -24153.2436          +0.0752\n",
      "        17      -24153.1337          +0.1098\n",
      "        18      -24152.9464          +0.1873\n",
      "        19      -24152.6444          +0.3021\n",
      "        20      -24152.2781          +0.3663\n",
      "        21      -24151.9285          +0.3497\n",
      "        22      -24151.5817          +0.3468\n",
      "        23      -24151.1677          +0.4140\n",
      "        24      -24150.7024          +0.4653\n",
      "        25      -24150.3312          +0.3712\n",
      "        26      -24150.1822          +0.1490\n",
      "        27      -24150.1648          +0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/benh_nhan.pkl\n",
      "Training Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        28      -24150.1637          +0.0011\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for cname in class_names:\n",
    "  print(\"====\", cname)\n",
    "    # convert all vectors to the cluster index\n",
    "    # dataset['cname'] = [O^1, ... O^R]\n",
    "    # O^r = (c1, c2, ... ct, ... cT)\n",
    "    # O^r size T x 1\n",
    "  train_dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "    \n",
    "  # Initialize Model\n",
    "#   n = dict_components[cname]\n",
    "#   startprob = np.zeros(n)\n",
    "#   startprob[0] = 1.0\n",
    "#   transmat = np.diag(np.full(n,1))\n",
    "\n",
    "#   hmm = hmmlearn.hmm.GMMHMM(\n",
    "#     n_components=n, \n",
    "#     n_mix = 4, random_state=10, n_iter=500, verbose=True,\n",
    "#     params='mctw', init_params='mct',\n",
    "#     startprob_prior=startprob,\n",
    "#     transmat_prior=transmat,\n",
    "#   )\n",
    "\n",
    "\n",
    "  if cname == \"toi\":\n",
    "#     # =================================================================\n",
    "#     # toi |sil|~|t|~|o|~|i|~|sil|\n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "      n_components=11, random_state=10, n_iter=500, init_params='e', params='ste', verbose=True\n",
    "    ) \n",
    "    hmm.startprob_ = np.array([0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "      ])\n",
    "#     hmm.startprob_ = np.zeros(11)\n",
    "#     hmm.startprob_[0] = 1.0\n",
    "#     hmm.transmat_ = np.diag(np.full(11, 1))\n",
    "#     print(hmm.transmat_)\n",
    "\n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#       n_components=9, init_params='e', params='ste', verbose=True\n",
    "#     ) \n",
    "#     hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "#       ])\n",
    "\n",
    "  elif cname == \"nguoi\":\n",
    "    # =================================================================\n",
    "    # nguoi |sil|~|ng|~|u|~o|~|i|~|sil|\n",
    "    \n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(n_components=17, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "    hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ =np.array([\n",
    "        [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "    ])\n",
    "\n",
    "  elif cname == \"dich\":\n",
    "    # =================================================================\n",
    "    # dich |sil|~|d|~|i|~|c|~h|~|sil|\n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "      n_components=14, random_state=10, n_iter=500, init_params='e', params='ste', verbose=True\n",
    "    )\n",
    "    hmm.startprob_ = np.array([0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "      ])\n",
    "\n",
    "\n",
    "  elif cname == \"theo\":\n",
    "    # =================================================================\n",
    "    # theo |sil|~|th|~|e|~|o|~|sil|\n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "      n_components=11, random_state=10, n_iter=500, init_params='e', params='ste', verbose=True\n",
    "    )\n",
    "#     hmm.startprob_ = np.zeros(11)\n",
    "#     hmm.startprob_[0] = 1.0\n",
    "#     hmm.transmat_ = np.diag(np.full(11, 1))\n",
    "    hmm.startprob_ = np.array([0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "      ])\n",
    "\n",
    "\n",
    "  elif cname == \"benh_nhan\":\n",
    "    # =================================================================\n",
    "    # benh_nhan |sil|~|b|~|e|~|nh|~|silent|~|nh|~|a|~|n|~|sil|  \n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "        n_components=21, random_state=10, n_iter=500, init_params='e', params='ste', verbose=True\n",
    "    )\n",
    "#     hmm.startprob_ = np.zeros(21)\n",
    "#     hmm.startprob_[0] = 1.0\n",
    "#     hmm.transmat_ = np.diag(np.full(21, 1))\n",
    "    hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "    ])\n",
    "\n",
    "#   if cname[:4] != \"test\":\n",
    "  X = np.concatenate(train_dataset[cname])\n",
    "#   lengths = list([len(x) for x in train_dataset[cname]])\n",
    "#       print(\"training class\", cname)\n",
    "#       print(X.shape, lengths, len(lengths))\n",
    "  hmm.fit(X)\n",
    "#       print(hmm.transmat_)\n",
    "  models[cname] = hmm\n",
    "  with open(os.path.join(\"models\", cname + \".pkl\"), \"wb\") as file: \n",
    "    pickle.dump(models[cname], file)\n",
    "    print(\"Training done. Model has been dump to \", os.path.join(\"models\", cname + \".pkl\"))\n",
    "print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing and Labeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apple/anaconda3/envs/voice/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (9175, 36)\n",
      "centers (20, 36)\n",
      "centers (20, 36)\n",
      "==================================\n",
      "test_toi\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.5643564356435643 ,true:  57 ,total_word:  101\n",
      "==================================\n",
      "test_nguoi\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.19480519480519481 ,true:  15 ,total_word:  77\n",
      "==================================\n",
      "test_theo\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.0 ,true:  0 ,total_word:  16\n",
      "==================================\n",
      "test_dich\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.8 ,true:  28 ,total_word:  35\n",
      "==================================\n",
      "test_benh_nhan\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.0 ,true:  0 ,total_word:  101\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "class_tests = [\"test_toi\", \"test_nguoi\", \"test_theo\", \"test_dich\", \"test_benh_nhan\"]\n",
    "print(\"Testing and Labeling\")\n",
    "testset = {}\n",
    "for name in class_tests:\n",
    "  testset[name] = get_class_data(os.path.join(\"test\", name))\n",
    "\n",
    "  # Get all vectors in the datasets\n",
    "all_train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in testset.items()], axis=0)\n",
    "print(\"vectors\", all_train_vectors.shape)\n",
    "  # Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_train_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "for name in class_tests:\n",
    "  testset[name] = list([kmeans.predict(v).reshape(-1,1) for v in testset[name]])\n",
    "\n",
    "for true_cname in class_tests:\n",
    "  if true_cname[:4] == \"test\":\n",
    "    print(\"==================================\")\n",
    "    print(true_cname)\n",
    "    print(\"==================================\")\n",
    "\n",
    "    lname = true_cname[5:]\n",
    "    totalWord = 0\n",
    "    true = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for O in testset[true_cname]:\n",
    "      totalWord += 1\n",
    "      scores = {}\n",
    "      for cname, model in models.items():\n",
    "        if cname[:4] != \"test\":\n",
    "          score = model.score(O, [len(O)])\n",
    "          scores[cname] = score\n",
    "#     print(scores)\n",
    "      srt = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "#     print(srt[0])\n",
    "\n",
    "      if srt[0][0] == lname:\n",
    "        true += 1\n",
    "    accuracy = true/totalWord\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"!note: test_folder must contain wavs that it records exactly the word which be trained\")\n",
    "    print(\"accuracy: \", accuracy, \",true: \", true, \",total_word: \", totalWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('voice': conda)",
   "language": "python",
   "name": "python37664bitvoicecondadb91d8c3466a4438829f78a16d8d338a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
