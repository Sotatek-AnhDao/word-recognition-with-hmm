{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "  y, sr = librosa.load(file_path) # read .wav file\n",
    "  hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "  win_length = math.floor(sr*0.025) # 25ms frame\n",
    "  # mfcc is 12 x T matrix\n",
    "  mfcc = librosa.feature.mfcc(\n",
    "      y, sr, n_mfcc=12, n_fft=1024,\n",
    "      hop_length=hop_length, win_length=win_length)\n",
    "  # substract mean from mfcc --> normalize mfcc\n",
    "  mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "  # delta feature 1st order and 2nd order\n",
    "  delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "  delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "  # X is 36 x T\n",
    "  X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "  # return T x 36 (transpose of X)\n",
    "  return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "  files = os.listdir(data_dir)\n",
    "  mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "  return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=20):\n",
    "  kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "  kmeans.fit(X)\n",
    "  print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "  return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apple/anaconda3/envs/voice/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (15146, 36)\n",
      "centers (20, 36)\n",
      "centers (20, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -7256.9265             +nan\n",
      "         2       -5841.6465       +1415.2800\n",
      "         3       -5196.9067        +644.7398\n",
      "         4       -4875.4758        +321.4309\n",
      "         5       -4667.0669        +208.4088\n",
      "         6       -4597.3097         +69.7572\n",
      "         7       -4565.5705         +31.7392\n",
      "         8       -4546.4731         +19.0974\n",
      "         9       -4525.3657         +21.1074\n",
      "        10       -4489.2885         +36.0771\n",
      "         1       -8393.7039             +nan\n",
      "         2       -5531.8465       +2861.8574\n",
      "         3       -4899.8848        +631.9617\n",
      "         4       -4484.4928        +415.3920\n",
      "         5       -4328.4898        +156.0031\n",
      "         6       -4252.6606         +75.8292\n",
      "         7       -4210.1671         +42.4935\n",
      "         8       -4143.3980         +66.7691\n",
      "         9       -4056.5979         +86.8002\n",
      "        10       -3921.2540        +135.3439\n",
      "         1       -9153.0046             +nan\n",
      "         2       -6394.7938       +2758.2108\n",
      "         3       -5798.1411        +596.6527\n",
      "         4       -5540.9885        +257.1526\n",
      "         5       -5459.5780         +81.4105\n",
      "         6       -5422.7530         +36.8250\n",
      "         7       -5398.8376         +23.9154\n",
      "         8       -5354.3576         +44.4800\n",
      "         9       -5282.7396         +71.6180\n",
      "        10       -5236.9210         +45.8186\n",
      "         1       -6729.1302             +nan\n",
      "         2       -5588.9125       +1140.2178\n",
      "         3       -5112.2687        +476.6437\n",
      "         4       -4860.3824        +251.8864\n",
      "         5       -4712.0132        +148.3691\n",
      "         6       -4640.8605         +71.1527\n",
      "         7       -4612.7312         +28.1293\n",
      "         8       -4600.9624         +11.7689\n",
      "         9       -4594.1477          +6.8147\n",
      "        10       -4586.8218          +7.3259\n",
      "         1      -14727.7918             +nan\n",
      "         2      -11459.7506       +3268.0412\n",
      "         3      -10669.2784        +790.4722\n",
      "         4      -10263.8527        +405.4257\n",
      "         5      -10069.7811        +194.0716\n",
      "         6       -9967.3401        +102.4410\n",
      "         7       -9880.9592         +86.3809\n",
      "         8       -9794.1027         +86.8565\n",
      "         9       -9720.0142         +74.0885\n",
      "        10       -9646.0871         +73.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing and Labeling\n",
      "==================================\n",
      "test_toi\n",
      "==================================\n",
      "{'toi': -45.25015650248858, 'nguoi': -726.385376966348, 'dich': -554.4902736671661, 'theo': -100.91716049694651, 'benh_nhan': -103.40491498325636}\n",
      "{'toi': -49.096324988484234, 'nguoi': -551.4604198180408, 'dich': -178.59072774884038, 'theo': -64.60260010659331, 'benh_nhan': -102.37377285066593}\n",
      "{'toi': -38.15037593832928, 'nguoi': -301.488687588137, 'dich': -144.94075210377625, 'theo': -45.21854734619076, 'benh_nhan': -73.27497813399228}\n",
      "{'toi': -59.02527459171824, 'nguoi': -123.69739559884415, 'dich': -93.89957655939872, 'theo': -67.08091159045115, 'benh_nhan': -82.47789613460573}\n",
      "{'toi': -77.1334632006309, 'nguoi': -123.9005134573428, 'dich': -133.0151324895969, 'theo': -78.46443551791984, 'benh_nhan': -91.80110684609545}\n",
      "{'toi': -58.5979326516364, 'nguoi': -1044.3570981658022, 'dich': -457.53150770709146, 'theo': -83.38813954606576, 'benh_nhan': -111.43091272974978}\n",
      "{'toi': -103.91018862841288, 'nguoi': -781.392160820384, 'dich': -308.9068040582754, 'theo': -184.27506224906784, 'benh_nhan': -141.77217825378608}\n",
      "{'toi': -46.49794196566635, 'nguoi': -99.63936070832065, 'dich': -169.83420668818252, 'theo': -66.17290865819798, 'benh_nhan': -80.8045638065017}\n",
      "{'toi': -34.81187887754475, 'nguoi': -297.3133791823157, 'dich': -139.8289128439704, 'theo': -56.03778027817315, 'benh_nhan': -67.82181466728392}\n",
      "{'toi': -32.741348296036854, 'nguoi': -293.5630131803409, 'dich': -127.82206904875282, 'theo': -29.027612387807885, 'benh_nhan': -66.17274492798346}\n",
      "{'toi': -37.48540375303673, 'nguoi': -58.801982836410836, 'dich': -122.86382792149773, 'theo': -42.38238243905735, 'benh_nhan': -51.99352074722897}\n",
      "{'toi': -91.8910894772647, 'nguoi': -109.57078414447629, 'dich': -117.12710725625892, 'theo': -139.0322670136201, 'benh_nhan': -129.09415304072252}\n",
      "{'toi': -42.821088785535984, 'nguoi': -551.8458604620096, 'dich': -133.03900477646414, 'theo': -55.520349529935395, 'benh_nhan': -82.73097957507314}\n",
      "{'toi': -66.66393794285258, 'nguoi': -683.9542438330826, 'dich': -878.6078026083059, 'theo': -103.48380722300062, 'benh_nhan': -85.34198078111343}\n",
      "{'toi': -84.2396214045901, 'nguoi': -671.2025324868405, 'dich': -418.22305180878334, 'theo': -98.88889733981912, 'benh_nhan': -107.59456372916534}\n",
      "{'toi': -31.633723356095626, 'nguoi': -26.813162249622284, 'dich': -98.65751836179071, 'theo': -39.66023537262623, 'benh_nhan': -28.78033472217665}\n",
      "{'toi': -69.08001692990428, 'nguoi': -497.9707661017472, 'dich': -100.69732752643304, 'theo': -135.58194917441912, 'benh_nhan': -102.580707646287}\n",
      "{'toi': -60.2573389364164, 'nguoi': -124.11446707133484, 'dich': -203.00139403119815, 'theo': -100.15110411221906, 'benh_nhan': -85.97209850208877}\n",
      "{'toi': -33.69308747325054, 'nguoi': -310.298031020277, 'dich': -75.09588406425692, 'theo': -42.25234034376949, 'benh_nhan': -60.8170542771444}\n",
      "{'toi': -56.754478509985304, 'nguoi': -78.5873150676105, 'dich': -136.00913222026273, 'theo': -80.25215719752137, 'benh_nhan': -80.50354603159252}\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.9 ,true:  18 ,total_word:  20\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  class_names = [\"toi\", \"nguoi\", \"dich\",  \"theo\", \"benh_nhan\", \"test_toi\"]\n",
    "  dataset = {}\n",
    "  train_dataset = {}\n",
    "  for cname in class_names:\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "    if cname[:4] != \"test\":\n",
    "#         print(f\"Load {cname} dataset to train\")\n",
    "        train_dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "#   # Get all vectors in the datasets\n",
    "#   all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "#   print(\"vectors\", all_vectors.shape)\n",
    "#   # Run K-Means algorithm to get clusters\n",
    "#   kmeans = clustering(all_vectors)\n",
    "#   print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "  # Get all vectors in the datasets\n",
    "  all_train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in train_dataset.items()], axis=0)\n",
    "  print(\"vectors\", all_train_vectors.shape)\n",
    "  # Run K-Means algorithm to get clusters\n",
    "  kmeans = clustering(all_train_vectors)\n",
    "  print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "  models = {}\n",
    "  for cname in class_names:\n",
    "    class_vectors = dataset[cname]\n",
    "    # convert all vectors to the cluster index\n",
    "    # dataset['cname'] = [O^1, ... O^R]\n",
    "    # O^r = (c1, c2, ... ct, ... cT)\n",
    "    # O^r size T x 1\n",
    "    dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "        \n",
    "    # =================================================================\n",
    "    # toi |t|~|o|~|i|\n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#       n_components=9, init_params='e', params='ste', verbose=True\n",
    "#     ) \n",
    "#     hmm.startprob_ = np.array([0.6, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "#       ])\n",
    "\n",
    "    # =================================================================\n",
    "    # nguoi |ng|~|uo|~|i|\n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#       n_components=15, init_params='e', params='ste', verbose=True\n",
    "#     )\n",
    "#     hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],    \n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],    \n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],    \n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "#       ])\n",
    "\n",
    "    # =================================================================\n",
    "    # dich |d|~|i|~|ch|\n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#       n_components=9, init_params='e', params='ste', verbose=True\n",
    "#     )\n",
    "#     hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "#       ])\n",
    "\n",
    "    # =================================================================\n",
    "    # theo |th|~|e|~|o|\n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#       n_components=9, init_params='e', params='ste', verbose=True\n",
    "#     )\n",
    "#     hmm.startprob_ = np.array([0.6, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.1, 0.3, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.2, 0.3, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.3, 0.3, 0.4, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.1, 0.4, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.2, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "#       ])\n",
    "\n",
    "    # =================================================================\n",
    "    # benh_nhan |b|~|e|~|nh|~|silent|~|nh|~|a|~|n|  \n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#         n_components=21, init_params='e', params='ste', verbose=True\n",
    "#     )\n",
    "#     hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "#     ])\n",
    "\n",
    "    if cname[:4] != 'test':\n",
    "      X = np.concatenate(dataset[cname])\n",
    "      lengths = list([len(x) for x in dataset[cname]])\n",
    "#       print(\"training class\", cname)\n",
    "#       print(X.shape, lengths, len(lengths))\n",
    "      hmm.fit(X, lengths=lengths)\n",
    "      models[cname] = hmm\n",
    "#       print(\"Training done\")\n",
    "\n",
    "  print(\"Testing and Labeling\")\n",
    "  for true_cname in class_names:\n",
    "    if true_cname[:4] == \"test\":\n",
    "      print(\"==================================\")\n",
    "      print(true_cname)\n",
    "      print(\"==================================\")\n",
    "    \n",
    "      lname = true_cname[5:]\n",
    "      totalWord = 0\n",
    "      true = 0\n",
    "      accuracy = 0\n",
    "    \n",
    "      for O in dataset[true_cname]:\n",
    "        totalWord += 1\n",
    "        scores = {}\n",
    "        for cname, model in models.items():\n",
    "          if cname[:4] != \"test\":\n",
    "            score = model.score(O, [len(O)])\n",
    "            scores[cname] = score\n",
    "        print(scores)\n",
    "        srt = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "#         print(srt[0])\n",
    "        if srt[0][0] == lname:\n",
    "            true += 1\n",
    "      accuracy = true/totalWord\n",
    "      print(\"--------------------------------------------\")\n",
    "      print(\"!note: test_folder must contain wavs that it records exactly the word which be trained\")\n",
    "      print(\"accuracy: \", accuracy, \",true: \", true, \",total_word: \", totalWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('voice': conda)",
   "language": "python",
   "name": "python37664bitvoicecondadb91d8c3466a4438829f78a16d8d338a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
