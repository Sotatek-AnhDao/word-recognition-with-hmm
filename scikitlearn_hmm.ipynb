{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "  y, sr = librosa.load(file_path) # read .wav file\n",
    "  hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "  win_length = math.floor(sr*0.025) # 25ms frame\n",
    "  # mfcc is 12 x T matrix\n",
    "  mfcc = librosa.feature.mfcc(\n",
    "      y, sr, n_mfcc=12, n_fft=1024,\n",
    "      hop_length=hop_length, win_length=win_length)\n",
    "  # substract mean from mfcc --> normalize mfcc\n",
    "  mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "  # delta feature 1st order and 2nd order\n",
    "  delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "  delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "  # X is 36 x T\n",
    "  X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "  # return T x 36 (transpose of X)\n",
    "  return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "  files = os.listdir(data_dir)\n",
    "  mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "  return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=20):\n",
    "  kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "  kmeans.fit(X)\n",
    "  print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "  return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apple/anaconda3/envs/voice/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (29941, 36)\n",
      "centers (20, 36)\n",
      "centers (20, 36)\n",
      "==== toi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -12618.7346             +nan\n",
      "         2       -9559.5890       +3059.1455\n",
      "         3       -8256.4756       +1303.1134\n",
      "         4       -7830.6025        +425.8731\n",
      "         5       -7678.4578        +152.1447\n",
      "         6       -7596.3506         +82.1072\n",
      "         7       -7537.9307         +58.4200\n",
      "         8       -7502.1063         +35.8244\n",
      "         9       -7483.4973         +18.6090\n",
      "        10       -7462.3849         +21.1124\n",
      "        11       -7420.5560         +41.8289\n",
      "        12       -7372.0105         +48.5456\n",
      "        13       -7335.6191         +36.3914\n",
      "        14       -7297.3025         +38.3166\n",
      "        15       -7225.6105         +71.6920\n",
      "        16       -7171.9298         +53.6807\n",
      "        17       -7139.6455         +32.2842\n",
      "        18       -7120.3916         +19.2539\n",
      "        19       -7101.9216         +18.4700\n",
      "        20       -7082.4747         +19.4470\n",
      "        21       -7071.3992         +11.0755\n",
      "        22       -7065.3947          +6.0045\n",
      "        23       -7059.6504          +5.7443\n",
      "        24       -7053.7549          +5.8955\n",
      "        25       -7047.9130          +5.8419\n",
      "        26       -7040.2447          +7.6683\n",
      "        27       -7031.0197          +9.2250\n",
      "        28       -7016.7493         +14.2704\n",
      "        29       -6998.2090         +18.5403\n",
      "        30       -6983.2504         +14.9587\n",
      "        31       -6976.5873          +6.6631\n",
      "        32       -6971.4033          +5.1840\n",
      "        33       -6959.8610         +11.5423\n",
      "        34       -6941.6573         +18.2037\n",
      "        35       -6925.5524         +16.1049\n",
      "        36       -6916.0686          +9.4838\n",
      "        37       -6913.9666          +2.1020\n",
      "        38       -6911.4969          +2.4697\n",
      "        39       -6908.7820          +2.7150\n",
      "        40       -6907.8446          +0.9374\n",
      "        41       -6907.3786          +0.4659\n",
      "        42       -6906.7143          +0.6643\n",
      "        43       -6905.9946          +0.7197\n",
      "        44       -6905.5818          +0.4127\n",
      "        45       -6905.3654          +0.2165\n",
      "        46       -6905.2183          +0.1471\n",
      "        47       -6905.0954          +0.1229\n",
      "        48       -6904.9692          +0.1262\n",
      "        49       -6904.7961          +0.1731\n",
      "        50       -6904.4298          +0.3663\n",
      "        51       -6902.9250          +1.5048\n",
      "        52       -6896.1826          +6.7424\n",
      "        53       -6887.5916          +8.5910\n",
      "        54       -6881.9227          +5.6690\n",
      "        55       -6880.5721          +1.3506\n",
      "        56       -6880.1970          +0.3751\n",
      "        57       -6880.0397          +0.1573\n",
      "        58       -6879.9634          +0.0764\n",
      "        59       -6879.9184          +0.0450\n",
      "        60       -6879.8835          +0.0349\n",
      "        61       -6879.8483          +0.0352\n",
      "        62       -6879.8072          +0.0411\n",
      "        63       -6879.7575          +0.0496\n",
      "        64       -6879.6992          +0.0584\n",
      "        65       -6879.6325          +0.0666\n",
      "        66       -6879.5578          +0.0747\n",
      "        67       -6879.4746          +0.0832\n",
      "        68       -6879.3850          +0.0896\n",
      "        69       -6879.2968          +0.0882\n",
      "        70       -6879.2216          +0.0752\n",
      "        71       -6879.1632          +0.0585\n",
      "        72       -6879.0951          +0.0680\n",
      "        73       -6878.8867          +0.2084\n",
      "        74       -6878.1595          +0.7272\n",
      "        75       -6877.0127          +1.1469\n",
      "        76       -6876.4001          +0.6126\n",
      "        77       -6876.2039          +0.1961\n",
      "        78       -6876.1397          +0.0642\n",
      "        79       -6876.1163          +0.0234\n",
      "        80       -6876.1062          +0.0101\n",
      "        81       -6876.1006          +0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/toi.pkl\n",
      "==== nguoi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -16207.7455             +nan\n",
      "         2      -10939.4866       +5268.2589\n",
      "         3       -9505.9488       +1433.5378\n",
      "         4       -8981.9445        +524.0043\n",
      "         5       -8811.5810        +170.3635\n",
      "         6       -8718.1838         +93.3972\n",
      "         7       -8636.4100         +81.7738\n",
      "         8       -8537.7101         +98.6999\n",
      "         9       -8415.2706        +122.4395\n",
      "        10       -8363.8998         +51.3708\n",
      "        11       -8334.5774         +29.3224\n",
      "        12       -8266.0960         +68.4814\n",
      "        13       -8250.0272         +16.0688\n",
      "        14       -8221.6973         +28.3299\n",
      "        15       -8202.5936         +19.1037\n",
      "        16       -8197.5010          +5.0926\n",
      "        17       -8195.9132          +1.5879\n",
      "        18       -8193.9509          +1.9623\n",
      "        19       -8191.2969          +2.6540\n",
      "        20       -8189.2602          +2.0367\n",
      "        21       -8187.1344          +2.1258\n",
      "        22       -8182.7682          +4.3661\n",
      "        23       -8159.9543         +22.8139\n",
      "        24       -8046.6090        +113.3453\n",
      "        25       -7994.0611         +52.5479\n",
      "        26       -7992.8154          +1.2456\n",
      "        27       -7992.6241          +0.1913\n",
      "        28       -7992.4759          +0.1482\n",
      "        29       -7992.3724          +0.1034\n",
      "        30       -7992.3053          +0.0671\n",
      "        31       -7992.2635          +0.0418\n",
      "        32       -7992.2379          +0.0256\n",
      "        33       -7992.2218          +0.0161\n",
      "        34       -7992.2110          +0.0108\n",
      "        35       -7992.2031          +0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/nguoi.pkl\n",
      "==== dich\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -16764.9036             +nan\n",
      "         2      -10561.6737       +6203.2299\n",
      "         3       -9399.6149       +1162.0588\n",
      "         4       -8715.6186        +683.9963\n",
      "         5       -8401.3145        +314.3040\n",
      "         6       -8248.3788        +152.9357\n",
      "         7       -8159.8562         +88.5226\n",
      "         8       -8080.7602         +79.0960\n",
      "         9       -8011.0868         +69.6734\n",
      "        10       -7978.2307         +32.8561\n",
      "        11       -7958.7307         +19.5000\n",
      "        12       -7938.1482         +20.5826\n",
      "        13       -7884.3894         +53.7587\n",
      "        14       -7874.8555          +9.5340\n",
      "        15       -7872.4593          +2.3962\n",
      "        16       -7871.4896          +0.9697\n",
      "        17       -7870.8908          +0.5988\n",
      "        18       -7870.4257          +0.4652\n",
      "        19       -7870.0282          +0.3975\n",
      "        20       -7869.6907          +0.3375\n",
      "        21       -7869.4552          +0.2355\n",
      "        22       -7869.3201          +0.1351\n",
      "        23       -7869.2165          +0.1036\n",
      "        24       -7869.0408          +0.1758\n",
      "        25       -7868.6126          +0.4281\n",
      "        26       -7867.9297          +0.6829\n",
      "        27       -7867.5204          +0.4093\n",
      "        28       -7867.4117          +0.1086\n",
      "        29       -7867.3836          +0.0282\n",
      "        30       -7867.3748          +0.0087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/dich.pkl\n",
      "==== theo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -14192.1547             +nan\n",
      "         2      -11385.0854       +2807.0694\n",
      "         3       -9983.9413       +1401.1440\n",
      "         4       -9592.6965        +391.2449\n",
      "         5       -9453.9016        +138.7949\n",
      "         6       -9393.1079         +60.7937\n",
      "         7       -9340.1825         +52.9254\n",
      "         8       -9272.5171         +67.6654\n",
      "         9       -9209.5211         +62.9960\n",
      "        10       -9139.7613         +69.7598\n",
      "        11       -9063.4370         +76.3243\n",
      "        12       -9002.2288         +61.2082\n",
      "        13       -8902.3676         +99.8612\n",
      "        14       -8844.2563         +58.1113\n",
      "        15       -8823.8607         +20.3956\n",
      "        16       -8820.1397          +3.7210\n",
      "        17       -8815.3967          +4.7430\n",
      "        18       -8804.9107         +10.4860\n",
      "        19       -8796.0209          +8.8898\n",
      "        20       -8782.0640         +13.9569\n",
      "        21       -8762.7489         +19.3151\n",
      "        22       -8749.5973         +13.1515\n",
      "        23       -8740.5955          +9.0018\n",
      "        24       -8717.4998         +23.0958\n",
      "        25       -8693.5282         +23.9716\n",
      "        26       -8681.7106         +11.8175\n",
      "        27       -8679.0939          +2.6167\n",
      "        28       -8678.3469          +0.7471\n",
      "        29       -8678.0837          +0.2632\n",
      "        30       -8677.9884          +0.0953\n",
      "        31       -8677.9497          +0.0386\n",
      "        32       -8677.9300          +0.0197\n",
      "        33       -8677.9168          +0.0132\n",
      "        34       -8677.9057          +0.0110\n",
      "        35       -8677.8950          +0.0108\n",
      "        36       -8677.8830          +0.0120\n",
      "        37       -8677.8678          +0.0152\n",
      "        38       -8677.8459          +0.0219\n",
      "        39       -8677.8107          +0.0351\n",
      "        40       -8677.7513          +0.0594\n",
      "        41       -8677.6526          +0.0987\n",
      "        42       -8677.5047          +0.1479\n",
      "        43       -8677.3239          +0.1808\n",
      "        44       -8677.1570          +0.1668\n",
      "        45       -8677.0407          +0.1163\n",
      "        46       -8676.9724          +0.0683\n",
      "        47       -8676.9321          +0.0403\n",
      "        48       -8676.9041          +0.0279\n",
      "        49       -8676.8803          +0.0238\n",
      "        50       -8676.8572          +0.0232\n",
      "        51       -8676.8333          +0.0239\n",
      "        52       -8676.8086          +0.0247\n",
      "        53       -8676.7837          +0.0249\n",
      "        54       -8676.7596          +0.0241\n",
      "        55       -8676.7376          +0.0220\n",
      "        56       -8676.7188          +0.0188\n",
      "        57       -8676.7038          +0.0149\n",
      "        58       -8676.6928          +0.0110\n",
      "        59       -8676.6852          +0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/theo.pkl\n",
      "==== benh_nhan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -29113.7431             +nan\n",
      "         2      -20064.7182       +9049.0249\n",
      "         3      -17295.5385       +2769.1797\n",
      "         4      -16027.1239       +1268.4146\n",
      "         5      -15554.1689        +472.9550\n",
      "         6      -15395.7747        +158.3942\n",
      "         7      -15303.5720         +92.2027\n",
      "         8      -15236.6224         +66.9496\n",
      "         9      -15186.2865         +50.3359\n",
      "        10      -15142.8967         +43.3898\n",
      "        11      -15100.9303         +41.9664\n",
      "        12      -15058.6950         +42.2353\n",
      "        13      -15036.6322         +22.0627\n",
      "        14      -15025.4501         +11.1821\n",
      "        15      -15016.1514          +9.2987\n",
      "        16      -15008.0196          +8.1318\n",
      "        17      -15002.0370          +5.9826\n",
      "        18      -14997.2012          +4.8358\n",
      "        19      -14993.8550          +3.3461\n",
      "        20      -14990.3987          +3.4564\n",
      "        21      -14985.7231          +4.6756\n",
      "        22      -14978.8633          +6.8598\n",
      "        23      -14971.2242          +7.6392\n",
      "        24      -14965.5157          +5.7084\n",
      "        25      -14961.8547          +3.6610\n",
      "        26      -14959.8478          +2.0069\n",
      "        27      -14958.1892          +1.6586\n",
      "        28      -14957.2054          +0.9838\n",
      "        29      -14956.9051          +0.3003\n",
      "        30      -14956.7409          +0.1643\n",
      "        31      -14956.6208          +0.1201\n",
      "        32      -14956.5193          +0.1015\n",
      "        33      -14956.4246          +0.0947\n",
      "        34      -14956.3317          +0.0929\n",
      "        35      -14956.2395          +0.0922\n",
      "        36      -14956.1500          +0.0895\n",
      "        37      -14956.0659          +0.0840\n",
      "        38      -14955.9893          +0.0766\n",
      "        39      -14955.9189          +0.0704\n",
      "        40      -14955.8471          +0.0718\n",
      "        41      -14955.7501          +0.0971\n",
      "        42      -14955.5480          +0.2021\n",
      "        43      -14954.9651          +0.5829\n",
      "        44      -14953.4949          +1.4702\n",
      "        45      -14951.4870          +2.0078\n",
      "        46      -14950.0562          +1.4308\n",
      "        47      -14949.3032          +0.7531\n",
      "        48      -14948.8229          +0.4803\n",
      "        49      -14948.4461          +0.3768\n",
      "        50      -14948.1253          +0.3207\n",
      "        51      -14947.8493          +0.2760\n",
      "        52      -14947.6191          +0.2302\n",
      "        53      -14947.4374          +0.1817\n",
      "        54      -14947.3017          +0.1357\n",
      "        55      -14947.2026          +0.0991\n",
      "        56      -14947.1266          +0.0760\n",
      "        57      -14947.0587          +0.0679\n",
      "        58      -14946.9814          +0.0774\n",
      "        59      -14946.8694          +0.1119\n",
      "        60      -14946.6915          +0.1780\n",
      "        61      -14946.4488          +0.2427\n",
      "        62      -14946.2292          +0.2196\n",
      "        63      -14946.1116          +0.1176\n",
      "        64      -14946.0696          +0.0420\n",
      "        65      -14946.0560          +0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done. Model has been dump to  models/benh_nhan.pkl\n",
      "Training Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        66      -14946.0500          +0.0060\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"toi\", \"nguoi\", \"dich\",  \"theo\", \"benh_nhan\"]\n",
    "dataset = {}\n",
    "train_dataset = {}\n",
    "for cname in class_names:\n",
    "  dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "  if cname[:4] != \"test\":\n",
    "#         print(f\"Load {cname} dataset to train\")\n",
    "    train_dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "  # Get all vectors in the datasets\n",
    "all_train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in train_dataset.items()], axis=0)\n",
    "print(\"vectors\", all_train_vectors.shape)\n",
    "  # Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_train_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "models = {}\n",
    "for cname in class_names:\n",
    "  print(\"====\", cname)\n",
    "  class_vectors = dataset[cname]\n",
    "    # convert all vectors to the cluster index\n",
    "    # dataset['cname'] = [O^1, ... O^R]\n",
    "    # O^r = (c1, c2, ... ct, ... cT)\n",
    "    # O^r size T x 1\n",
    "  dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "    \n",
    "    \n",
    "  if cname == \"toi\":\n",
    "    # =================================================================\n",
    "    # toi |sil|~|t|~|o|~|i|~|sil|\n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "      n_components=9, random_state=0, n_iter=1000, init_params='e', params='ste', verbose=True\n",
    "    ) \n",
    "    hmm.startprob_ = np.array([0.6, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "      ])\n",
    "\n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#       n_components=9, init_params='e', params='ste', verbose=True\n",
    "#     ) \n",
    "#     hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "#       ])\n",
    "\n",
    "  elif cname == \"nguoi\":\n",
    "    # =================================================================\n",
    "    # nguoi |sil|~|ng|~|uo|~|i|~|sil|\n",
    "#     hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "#       n_components=11, init_params='e', params='ste', verbose=True\n",
    "#     )\n",
    "#     hmm.startprob_ = np.array([0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#         [0.1, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "#         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "#       ])\n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(n_components=12, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "    hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "    hmm.transmat_ =np.array([\n",
    "        [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "        [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "        [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "        [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "  elif cname == \"dich\":\n",
    "    # =================================================================\n",
    "    # dich |sil|~|d|~|i|~|ch|~|sil|\n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "      n_components=9, random_state=0, n_iter=1000, init_params='e', params='ste', verbose=True\n",
    "    )\n",
    "    hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "      ])\n",
    "\n",
    "\n",
    "  elif cname == \"theo\":\n",
    "    # =================================================================\n",
    "    # theo |sil|~|th|~|e|~|o|~|sil|\n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "      n_components=9, random_state=0, n_iter=1000, init_params='e', params='ste', verbose=True\n",
    "    )\n",
    "    hmm.startprob_ = np.array([0.6, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "      ])\n",
    "\n",
    "\n",
    "  elif cname == \"benh_nhan\":\n",
    "    # =================================================================\n",
    "    # benh_nhan |sil|~|b|~|e|~|nh|~|silent|~|nh|~|a|~|n|~|sil|  \n",
    "    hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "        n_components=23, random_state=0, n_iter=1000, init_params='e', params='ste', verbose=True\n",
    "    )\n",
    "    hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "        [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "    ])\n",
    "\n",
    "  if cname[:4] != \"test\":\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "#       print(\"training class\", cname)\n",
    "#       print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X, lengths=lengths)\n",
    "#       print(hmm.transmat_)\n",
    "    models[cname] = hmm\n",
    "    with open(os.path.join(\"models\", cname + \".pkl\"), \"wb\") as file: \n",
    "      pickle.dump(models[cname], file)\n",
    "      print(\"Training done. Model has been dump to \", os.path.join(\"models\", cname + \".pkl\"))\n",
    "print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing and Labeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apple/anaconda3/envs/voice/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (3262, 36)\n",
      "centers (20, 36)\n",
      "centers (20, 36)\n",
      "==================================\n",
      "test_toi\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.2 ,true:  4 ,total_word:  20\n",
      "==================================\n",
      "test_nguoi\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.0 ,true:  0 ,total_word:  20\n",
      "==================================\n",
      "test_theo\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.5 ,true:  10 ,total_word:  20\n",
      "==================================\n",
      "test_dich\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.05 ,true:  1 ,total_word:  20\n",
      "==================================\n",
      "test_benh_nhan\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.0 ,true:  0 ,total_word:  18\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "class_tests = [\"test_toi\", \"test_nguoi\", \"test_theo\", \"test_dich\", \"test_benh_nhan\"]\n",
    "print(\"Testing and Labeling\")\n",
    "testset = {}\n",
    "for name in class_tests:\n",
    "  testset[name] = get_class_data(os.path.join(\"data\", name))\n",
    "\n",
    "  # Get all vectors in the datasets\n",
    "all_train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in testset.items()], axis=0)\n",
    "print(\"vectors\", all_train_vectors.shape)\n",
    "  # Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_train_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "for name in class_tests:\n",
    "  testset[name] = list([kmeans.predict(v).reshape(-1,1) for v in testset[name]])\n",
    "\n",
    "for true_cname in class_tests:\n",
    "  if true_cname[:4] == \"test\":\n",
    "    print(\"==================================\")\n",
    "    print(true_cname)\n",
    "    print(\"==================================\")\n",
    "\n",
    "    lname = true_cname[5:]\n",
    "    totalWord = 0\n",
    "    true = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for O in testset[true_cname]:\n",
    "      totalWord += 1\n",
    "      scores = {}\n",
    "      for cname, model in models.items():\n",
    "        if cname[:4] != \"test\":\n",
    "          score = model.score(O, [len(O)])\n",
    "          scores[cname] = score\n",
    "#     print(scores)\n",
    "      srt = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "#     print(srt[0])\n",
    "\n",
    "      if srt[0][0] == lname:\n",
    "        true += 1\n",
    "    accuracy = true/totalWord\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"!note: test_folder must contain wavs that it records exactly the word which be trained\")\n",
    "    print(\"accuracy: \", accuracy, \",true: \", true, \",total_word: \", totalWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('voice': conda)",
   "language": "python",
   "name": "python37664bitvoicecondadb91d8c3466a4438829f78a16d8d338a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
